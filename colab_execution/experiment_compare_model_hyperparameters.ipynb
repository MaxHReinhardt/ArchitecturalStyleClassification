{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Compare Model Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone https://github.com/MaxHReinhardt/ArchitecturalStyleClassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = \"/content/ArchitecturalStyleClassification/src\"\n",
    "sys.path.append(os.path.abspath(py_file_location))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "\n",
    "from preprocessing import TrainSetDynamicNormalization, EvaluationSetStaticNormalization\n",
    "from model import MobileNetV1\n",
    "from train_model import train_with_early_stopping\n",
    "from evaluate_model import evaluate\n",
    "\n",
    "\n",
    "def compare_model_hyperparameter_configurations(width_multiplier_list, resolution_list, cbam_last_layer_variant_list,\n",
    "                                                cbam_all_layers_variant_list, train_csv, validation_csv):\n",
    "    \"\"\"\n",
    "    Performs grid search for given lists of model hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.003\n",
    "    weight_decay = 0\n",
    "    max_num_epochs = 100\n",
    "\n",
    "    # Check if CUDA (GPU) is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    for width_multiplier, resolution, cbam_last_layer, cbam_all_layers in itertools.product(width_multiplier_list,\n",
    "                                                                                            resolution_list,\n",
    "                                                                                            cbam_last_layer_variant_list,\n",
    "                                                                                            cbam_all_layers_variant_list):\n",
    "        train_set_object = TrainSetDynamicNormalization(resolution=resolution,\n",
    "                                                        train_csv=train_csv)\n",
    "        train_set = train_set_object.get_data()\n",
    "        normalization_mean, normalization_std = train_set_object.get_normalization_parameters()\n",
    "        validation_set = EvaluationSetStaticNormalization(resolution=resolution,\n",
    "                                                          evaluation_csv=validation_csv,\n",
    "                                                          normalization_mean=normalization_mean,\n",
    "                                                          normalization_std=normalization_std).get_data()\n",
    "\n",
    "        model = MobileNetV1(ch_in=3, n_classes=25, width_multiplier=width_multiplier,\n",
    "                            cbam_all_layers=cbam_all_layers, cbam_last_layer=cbam_last_layer)\n",
    "        model.to(device)\n",
    "\n",
    "        trained_model, train_loss_development, val_loss_development = train_with_early_stopping(model,\n",
    "                                                                                                train_set,\n",
    "                                                                                                validation_set,\n",
    "                                                                                                batch_size,\n",
    "                                                                                                learning_rate,\n",
    "                                                                                                max_num_epochs,\n",
    "                                                                                                device,\n",
    "                                                                                                weight_decay)\n",
    "\n",
    "        model_name = f\"{width_multiplier}-MobileNetV1-{resolution}_\" \\\n",
    "                     f\"{'cbam_last_layer' if cbam_last_layer else ''}_{'cbam_all_layers' if cbam_all_layers else ''}\"\n",
    "        model_path = os.path.join(\"stored_models/\", model_name + \".pth\")\n",
    "        torch.save(trained_model.state_dict(), model_path)\n",
    "\n",
    "        accuracy, _, avg_loss, avg_prediction_time = evaluate(trained_model,\n",
    "                                                              validation_set,\n",
    "                                                              batch_size,\n",
    "                                                              device)\n",
    "\n",
    "        print(f\"{model_name} evaluation -- Accuracy: {accuracy}, Average loss: {avg_loss}, \"\n",
    "              f\"Average prediction time (seconds): {avg_prediction_time}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir stored_models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip /content/gdrive/MyDrive/data.zip;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "width_multiplier_list = [1, 0.75, 0.5]\n",
    "resolution_list = [384]\n",
    "cbam_last_layer_variant_list = [False]\n",
    "cbam_all_layers_variant_list = [True]\n",
    "train_csv = \"data/dataset/train_annotation.csv\"\n",
    "validation_csv = \"data/dataset/validation_annotation.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_model_hyperparameter_configurations(width_multiplier_list, resolution_list, cbam_last_layer_variant_list, cbam_all_layers_variant_list, train_csv, validation_csv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

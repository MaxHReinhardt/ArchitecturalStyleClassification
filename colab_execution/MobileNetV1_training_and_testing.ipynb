{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Test MobileNetV1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone https://github.com/MaxHReinhardt/ArchitecturalStyleClassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "py_file_location = \"/content/ArchitecturalStyleClassification/src\"\n",
    "sys.path.append(os.path.abspath(py_file_location))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import ArchitecturalStylesDataset\n",
    "from models import MobileNetV1\n",
    "from train_model import train_for_n_epochs, train_with_early_stopping\n",
    "from evaluate_model import evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip /content/gdrive/MyDrive/data.zip;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train for n epochs\n",
    "\n",
    "model = MobileNetV1(ch_in=3, n_classes=25, with_cbam=True)\n",
    "\n",
    "train_transforms = v2.Compose(\n",
    "    [\n",
    "        # Convert to image tensor with datatype uint8\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.uint8, scale=True),\n",
    "        # Augment data\n",
    "        v2.RandomResizedCrop(size=(320, 320), antialias=True),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=None),\n",
    "        v2.RandomRotation(degrees=15),\n",
    "        # v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Apply random affine transformations\n",
    "        # v2.RandomGrayscale(p=0.1),\n",
    "        # Convert to float32 and normalize\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and SD\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = ArchitecturalStylesDataset(\n",
    "    csv_file=\"data/dataset/train_annotation.csv\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.003\n",
    "num_epochs = 10\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "MobileNetV1_cbam_model, train_loss_development = train_for_n_epochs(model, train_set, batch_size, learning_rate, num_epochs, device)\n",
    "print(f\"Losses: {train_loss_development}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot Losses\n",
    "plt.plot(train_loss_development)\n",
    "plt.xlabel('Number of Training Examples (10 batches a 64 datapoints)')\n",
    "plt.ylabel('Cross Entropy Error')\n",
    "plt.title('Plot of Losses')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train with early stopping\n",
    "\n",
    "model = MobileNetV1(ch_in=3, n_classes=25, with_cbam=True)\n",
    "\n",
    "train_transforms = v2.Compose(\n",
    "    [\n",
    "        # Convert to image tensor with datatype uint8\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.uint8, scale=True),\n",
    "        # Augment data\n",
    "        v2.RandomResizedCrop(size=(320, 320), antialias=True),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=None),\n",
    "        v2.RandomRotation(degrees=15),\n",
    "        # v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Apply random affine transformations\n",
    "        # v2.RandomGrayscale(p=0.1),\n",
    "        # Convert to float32 and normalize\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and SD\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = ArchitecturalStylesDataset(\n",
    "    csv_file=\"data/dataset/train_annotation.csv\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "val_set = ArchitecturalStylesDataset(\n",
    "    csv_file=\"data/dataset/validation_annotation.csv\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.003\n",
    "max_num_epochs = 100\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "MobileNetV1_cbam_early_stopping, train_loss_development, val_loss_development = train_with_early_stopping(model, train_set, val_set,\n",
    "                                                                                        batch_size, learning_rate,\n",
    "                                                                                        max_num_epochs, device)\n",
    "print(f\"train_loss_development: {train_loss_development}\")\n",
    "print(f\"val_loss_development: {val_loss_development}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot train and validation loss development\n",
    "plt.plot(train_loss_development, label='Training Loss', color='blue')\n",
    "plt.plot(val_loss_development, label='Validation Loss', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross Entropy Error')\n",
    "plt.title('Plot of Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "accuracy, macro_f1, avg_loss = evaluate(MobileNetV1_cbam_model, train_set, batch_size, device)  # Use train set also for evaluation for testing\n",
    "print(f\"Accuracy on Train Set: {accuracy}\")\n",
    "print(f\"Macro F1 on  Train Set: {macro_f1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_set = ArchitecturalStylesDataset(\n",
    "    csv_file=\"data/dataset/validation_annotation.csv\",\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "accuracy, macro_f1, avg_loss = evaluate(MobileNetV1_cbam_model, validation_set, batch_size, device)  # Use train set also for evaluation for testing\n",
    "print(f\"Accuracy on validation set: {accuracy}\")\n",
    "print(f\"Macro F1 on  validation set: {macro_f1}\")\n",
    "print(f\"Average loss on validation set: {avg_loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
